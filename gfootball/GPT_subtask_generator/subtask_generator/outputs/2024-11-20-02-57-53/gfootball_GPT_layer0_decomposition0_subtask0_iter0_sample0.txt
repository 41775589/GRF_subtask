[DEBUG 02:58:42] git.cmd Popen(['git', 'version'], cwd=/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/gfootball/GPT_subtask_generator/subtask_generator, stdin=None, shell=False, universal_newlines=False)
[DEBUG 02:58:42] git.cmd Popen(['git', 'version'], cwd=/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/gfootball/GPT_subtask_generator/subtask_generator, stdin=None, shell=False, universal_newlines=False)
[INFO 02:58:42] root Saving to FileStorageObserver in results/sacred.
[DEBUG 02:58:42] pymarl Using capture mode "fd"
[INFO 02:58:42] pymarl Running command 'my_main'
[INFO 02:58:42] pymarl Started run with ID "1"
[DEBUG 02:58:42] pymarl Starting Heartbeat
[DEBUG 02:58:42] my_main Started
[WARNING 02:58:42] my_main CUDA flag use_cuda was switched OFF automatically because no CUDA devices are available!
AAAAAAAAAA namespace(runner='parallel', mac='basic_mac', env='gfootball', common_reward=True, reward_scalarisation='sum', env_args={'map_name': 'scenario_layer0_decomposition0_subtask0', 'num_agents': 2, 'representation': 'simple115', 'rewards': 'scoring, reward_layer0_decomposition0_subtask0_iter0_sample0', 'time_limit': 150, 'seed': 237012128}, batch_size_run=10, test_nepisode=30, test_interval=10000, test_greedy=True, log_interval=10000, runner_log_interval=10000, learner_log_interval=10000, t_max=10000, use_cuda=False, buffer_cpu_only=True, use_tensorboard=True, use_wandb=False, wandb_team=None, wandb_project=None, wandb_mode='offline', wandb_save_model=False, save_model=False, save_model_interval=50000, checkpoint_path='', evaluate=False, render=False, load_step=0, save_replay=False, local_results_path='results', gamma=0.99, batch_size=10, buffer_size=10, lr=0.0005, optim_alpha=0.99, optim_eps=1e-05, grad_norm_clip=10, add_value_last_step=True, agent='rnn', hidden_dim=128, obs_agent_id=True, obs_last_action=False, repeat_id=1, label='default_label', hypergroup=None, action_selector='soft_policies', agent_output_type='pi_logits', critic_type='ac_critic', decomposition_id=0, doe_classifier_cfg={'doe_type': 'mlp', 'load_doe_buffer_path': 'GRF_SUBTASK/doe_epymarl-main/results/buffer/grf', 'load_doe_name': 'load_mlp_classifier.pt', 'load_mode': 'train', 'mlp': {'batch_size': 512, 'hidden_sizes': [128], 'learning_rate': '1e-2', 'test_fraction': 0.1}, 'role_ids': {'task': [0, 1]}, 'save_classifier': True, 'save_doe_name': 'save_mlp_classifier.pt'}, entropy_coef=0.001, group_id=0, iter_id=0, layer_id=0, learner='actor_critic_learner', mask_before_softmax=True, name='ia2c', obs_individual_obs=False, q_nstep=5, sample_id=0, save_buffer=True, save_doe_cls=True, standardise_returns=False, standardise_rewards=True, target_update_interval_or_tau=0.01, time_stamp='2024-11-20-02-57-53', use_doe=False, use_rnn=True, seed=237012128, device='cpu')
[INFO 02:58:42] my_main Experiment Parameters:
[INFO 02:58:42] my_main 

{   'action_selector': 'soft_policies',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'pi_logits',
    'batch_size': 10,
    'batch_size_run': 10,
    'buffer_cpu_only': True,
    'buffer_size': 10,
    'checkpoint_path': '',
    'common_reward': True,
    'critic_type': 'ac_critic',
    'decomposition_id': 0,
    'doe_classifier_cfg': {   'doe_type': 'mlp',
                              'load_doe_buffer_path': 'GRF_SUBTASK/doe_epymarl-main/results/buffer/grf',
                              'load_doe_name': 'load_mlp_classifier.pt',
                              'load_mode': 'train',
                              'mlp': {   'batch_size': 512,
                                         'hidden_sizes': [   128],
                                         'learning_rate': '1e-2',
                                         'test_fraction': 0.1},
                              'role_ids': {   'task': [   0,
                                                          1]},
                              'save_classifier': True,
                              'save_doe_name': 'save_mlp_classifier.pt'},
    'entropy_coef': 0.001,
    'env': 'gfootball',
    'env_args': {   'map_name': 'scenario_layer0_decomposition0_subtask0',
                    'num_agents': 2,
                    'representation': 'simple115',
                    'rewards': 'scoring, '
                               'reward_layer0_decomposition0_subtask0_iter0_sample0',
                    'seed': 237012128,
                    'time_limit': 150},
    'evaluate': False,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'group_id': 0,
    'hidden_dim': 128,
    'hypergroup': None,
    'iter_id': 0,
    'label': 'default_label',
    'layer_id': 0,
    'learner': 'actor_critic_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'basic_mac',
    'mask_before_softmax': True,
    'name': 'ia2c',
    'obs_agent_id': True,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'q_nstep': 5,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'parallel',
    'runner_log_interval': 10000,
    'sample_id': 0,
    'save_buffer': True,
    'save_doe_cls': True,
    'save_model': False,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 237012128,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 10000,
    'target_update_interval_or_tau': 0.01,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 30,
    'time_stamp': '2024-11-20-02-57-53',
    'use_cuda': False,
    'use_doe': False,
    'use_rnn': True,
    'use_tensorboard': True,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[INFO 02:58:42] my_main *******************
[INFO 02:58:42] my_main Tensorboard logging dir:
[INFO 02:58:42] my_main /home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/doe_epymarl-main/results/tb_logs/2024-11-20-02-57-53/layer0_decomposition0_subtask0_iter0_sample0
[INFO 02:58:42] my_main *******************
[INFO 02:58:43] my_main Beginning training for 10000 timesteps
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:43] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "lost_score": count limit reached / disabled
[INFO 02:58:44] absl Episode reward: -1.00 score: [0, 1], steps: 126, FPS: 132.0, gameFPS: 359.3
[INFO 02:58:44] my_main t_env: 1476 / 10000
[INFO 02:58:44] my_main Estimated time left: 0 seconds. Time passed: 1 seconds
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:44] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:44] absl Episode reward: 0.00 score: [0, 0], steps: 40, FPS: 130.5, gameFPS: 345.8
[INFO 02:58:45] absl Episode reward: 0.00 score: [0, 0], steps: 65, FPS: 129.6, gameFPS: 375.7
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:45] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:45] absl Episode reward: 0.00 score: [0, 0], steps: 27, FPS: 117.8, gameFPS: 265.2
[INFO 02:58:46] absl Episode reward: 0.00 score: [0, 0], steps: 94, FPS: 134.5, gameFPS: 477.2
[INFO 02:58:46] absl Episode reward: 0.00 score: [0, 0], steps: 113, FPS: 130.6, gameFPS: 384.2
[DEBUG 02:58:46] absl Dump "lost_score": count limit reached / disabled
[INFO 02:58:46] absl Episode reward: -1.00 score: [0, 1], steps: 130, FPS: 133.7, gameFPS: 352.2
[INFO 02:58:46] absl Episode reward: 0.00 score: [0, 0], steps: 141, FPS: 135.3, gameFPS: 335.7
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:46] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:47] absl Episode reward: 0.00 score: [0, 0], steps: 135, FPS: 136.2, gameFPS: 363.2
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:47] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:48] absl Episode reward: 0.00 score: [0, 0], steps: 23, FPS: 118.2, gameFPS: 342.4
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:48] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:49] absl Episode reward: 0.00 score: [0, 0], steps: 142, FPS: 135.0, gameFPS: 429.2
[INFO 02:58:50] absl Episode reward: 0.00 score: [0, 0], steps: 146, FPS: 133.7, gameFPS: 310.7
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:50] absl Dump "lost_score": count limit reached / disabled
[INFO 02:58:50] absl Episode reward: -1.00 score: [0, 1], steps: 68, FPS: 117.8, gameFPS: 403.7
[DEBUG 02:58:51] absl Dump "lost_score": count limit reached / disabled
[INFO 02:58:51] absl Episode reward: -1.00 score: [0, 1], steps: 139, FPS: 132.7, gameFPS: 344.9
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:51] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:52] absl Episode reward: 0.00 score: [0, 0], steps: 95, FPS: 136.0, gameFPS: 331.8
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:52] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:53] absl Episode reward: 0.00 score: [0, 0], steps: 111, FPS: 131.5, gameFPS: 344.7
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[DEBUG 02:58:53] absl Dump "episode_done": count limit reached / disabled
[INFO 02:58:54] my_main Recent Stats | t_env:      10150 | Episode:       70
advantage_mean:            0.0022	agent_grad_norm:           0.1501	component_base_score_reward_mean: -0.2000	component_goal_distance_reward_mean:  0.0000
component_shot_on_target_reward_mean:  0.0000	component_successful_dribble_reward_mean:  0.0000	component_successful_pass_reward_mean:  0.0000	critic_grad_norm:          0.2378
critic_loss:               5.0549	ep_length_mean:          147.6000	final_reward_mean:        -0.2000	pg_loss:                   0.0036
pi_max:                    0.0638	q_taken_mean:             -0.0404	return_mean:              -0.0277	return_std:                0.6812
score_reward_mean:        -0.1000	target_mean:              -0.0382	td_error_abs:              0.2867	test_component_base_score_reward_mean: -0.0667
test_component_goal_distance_reward_mean:  0.0000	test_component_shot_on_target_reward_mean:  0.0000	test_component_successful_dribble_reward_mean:  0.0000	test_component_successful_pass_reward_mean:  0.0000
test_ep_length_mean:     134.8333	test_final_reward_mean:   -0.0667	test_return_mean:          0.1109	test_return_std:           0.4203
test_score_reward_mean:   -0.0333	
[INFO 02:58:54] my_main Save buffer to /home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/doe_epymarl-main/results/buffers/gfootball/2024-11-20-02-57-53 for DoE Classifier
/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/doe_epymarl-main/src/modules/doe/mlp_class.py:163: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  exp_buffers = torch.load(os.path.join(buffer_path))
[INFO 02:58:54] my_main Save buffer to /home/zihao/zihao/PycharmProjects/GRF_SUBTASK-1118/doe_epymarl-main/results/buffers/gfootball/2024-11-20-02-57-53 for DoE Classifier
[INFO 02:58:54] my_main Finished Training
Exiting Main
Stopping all threads
Thread Thread-1 is alive! Is daemon: False
Thread joined
Exiting script
[DEBUG 02:58:55] my_main Finished after 0:00:13.
[INFO 02:58:55] pymarl Completed after 0:00:13
[DEBUG 02:58:55] pymarl Stopping Heartbeat
